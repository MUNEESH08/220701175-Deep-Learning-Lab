# If running in a fresh notebook, install helpers (optional)
!pip install -q imageio
!pip install -q git+https://github.com/tensorflow/docs

# --- Imports ---
import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import time
import tensorflow as tf
from tensorflow.keras import layers
from IPython import display

print("TensorFlow version:", tf.__version__)

# --- Load and prepare the dataset ---
# load MNIST
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

# reshape and normalize to [-1, 1]
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]

BUFFER_SIZE = 60000
BATCH_SIZE = 256

train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

# --- Generator model ---
def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    # expected output shape: (None, 7, 7, 256)
    assert model.output_shape == (None, 7, 7, 256)

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # final layer: 1 channel (grayscale), tanh to produce outputs in [-1, 1]
    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 1)

    return model

generator = make_generator_model()
# quick smoke test
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
print("Generator output shape (smoke test):", generated_image.shape)

# show one generated image (untrained, random)
plt.imshow(generated_image[0, :, :, 0], cmap='gray')
plt.title("Untrained generator sample")
plt.axis('off')
plt.show()

# --- Discriminator model ---
def make_discriminator_model():
    model = tf.keras.Sequential()
    # kernel_size=(5,5), stride 2 reduces spatial dims
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))  # output logits

    return model

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print("Discriminator decision (smoke test):", decision.shape)

# --- Losses and optimizers ---
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

# --- Checkpointing ---
checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

# --- Training parameters ---
EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16

# Seed for visualizing progress (reused)
seed = tf.random.normal([num_examples_to_generate, noise_dim])

# --- Training step ---
@tf.function
def train_step(images):
    # images may have last batch smaller than BATCH_SIZE; handle that
    batch_size = tf.shape(images)[0]
    noise = tf.random.normal([batch_size, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss

# --- Image generation + saving ---
def generate_and_save_images(model, epoch, test_input):
    # Notice `training` is set to False so BatchNorm runs in inference mode
    predictions = model(test_input, training=False)
    # predictions are in [-1, 1] -> convert to [0,255]
    predictions = (predictions * 127.5 + 127.5).numpy().astype(np.uint8)

    fig = plt.figure(figsize=(4, 4))
    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i + 1)
        plt.imshow(predictions[i, :, :, 0], cmap='gray')
        plt.axis('off')

    # ensure output dir exists
    if not os.path.exists('./generated_images'):
        os.makedirs('./generated_images')

    plt.suptitle(f'Epoch {epoch}')
    fname = f'./generated_images/image_at_epoch_{epoch:04d}.png'
    plt.savefig(fname)
    plt.show()

# utility to display a single saved image
def display_image(epoch_no):
    fname = './generated_images/image_at_epoch_{:04d}.png'.format(epoch_no)
    return PIL.Image.open(fname)

# --- Training loop ---
def train(dataset, epochs):
    for epoch in range(epochs):
        start = time.time()

        gen_loss_avg = tf.keras.metrics.Mean()
        disc_loss_avg = tf.keras.metrics.Mean()

        for image_batch in dataset:
            g_loss, d_loss = train_step(image_batch)
            gen_loss_avg.update_state(g_loss)
            disc_loss_avg.update_state(d_loss)

        # Produce images for the GIF / inspection
        generate_and_save_images(generator, epoch + 1, seed)

        # Save the model every 15 epochs
        if (epoch + 1) % 15 == 0:
            checkpoint.save(file_prefix = checkpoint_prefix)

        print ('Time for epoch {} is {:.2f} sec | gen_loss {:.4f} | disc_loss {:.4f}'.format(
            epoch + 1, time.time()-start, gen_loss_avg.result(), disc_loss_avg.result()))

    # Generate after the final epoch
    generate_and_save_images(generator, epochs, seed)

# --- Run training ---
train(train_dataset, EPOCHS)

# Restore latest checkpoint (optional)
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

# Display the image from final epoch
display_image(EPOCHS)